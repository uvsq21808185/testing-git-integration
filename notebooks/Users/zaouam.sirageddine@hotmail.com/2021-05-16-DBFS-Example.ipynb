{"cells":[{"cell_type":"markdown","source":["## Overview\n\nThis notebook will show you how to create and query a table or DataFrame that you uploaded to DBFS. [DBFS](https://docs.databricks.com/user-guide/dbfs-databricks-file-system.html) is a Databricks File System that allows you to store data for querying inside of Databricks. This notebook assumes that you have a file already inside of DBFS that you would like to read from.\n\nThis notebook is written in **Python** so the default cell type is Python. However, you can use different languages by using the `%LANGUAGE` syntax. Python, Scala, SQL, and R are all supported.\n\nAuthor :\nZAOUAM Sirageddine"],"metadata":{}},{"cell_type":"code","source":["# File location and type\nfile_location = \"/FileStore/tables/distance_domicile_travail.csv\"\nfile_type = \"csv\"\n\n# CSV options\ninfer_schema = \"false\"\nfirst_row_is_header = \"false\"\ndelimiter = \",\"\n\n# The applied options are for CSV files. For other file types, these will be ignored.\ndf = spark.read.format(file_type) \\\n  .option(\"inferSchema\", infer_schema) \\\n  .option(\"header\", first_row_is_header) \\\n  .option(\"sep\", delimiter) \\\n  .load(file_location)\n\ndisplay(df) \n"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["# Create a view or table\n\ntemp_table_name = \"distance_domicile_travail_csv\"\n\ndf.createOrReplaceTempView(temp_table_name)"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["%sql\n\n/* Query the created temp table in a SQL cell */\n\nselect * from `distance_domicile_travail_csv`"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["# With this registered as a temp view, it will only be available to this particular notebook. If you'd like other users to be able to query this table, you can also create a table from the DataFrame.\n# Once saved, this table will persist across cluster restarts as well as allow various users across different notebooks to query this data.\n# To do so, choose your table name and uncomment the bottom line.\n\npermanent_table_name = \"distance_domicile_travail_csv\"\n\n# df.write.format(\"parquet\").saveAsTable(permanent_table_name)"],"metadata":{},"outputs":[],"execution_count":5}],"metadata":{"name":"2021-05-16 - DBFS Example","notebookId":2921376766971276},"nbformat":4,"nbformat_minor":0}